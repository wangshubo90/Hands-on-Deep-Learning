{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "# otherwise you have to call tf.keras.xxxx\n",
    "# you can also do this: from tensorflow.keras import layers\n",
    "# so that you can just call layers.xxxx instead of tf.keras.layers.xxx/keras.layers.xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version is: 2.0.0\n",
      "Keras version is : 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "print('Tensorflow version is: {}'.format(tf.__version__))\n",
    "print('Keras version is : {}'.format(keras.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n",
      "Data shape is : (60000, 28, 28)\n",
      "Data dtype is : uint8\n",
      "Memory used: 179.44 Mbs\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "print(\"Data shape is : {}\".format(X_train_full.shape))\n",
    "print(\"Data dtype is : {}\".format(X_train_full.dtype))\n",
    "print(\"Memory used: {:.2f} Mbs\".format(reduce(lambda x,y:x*y, X_train_full.shape)*4/1024/1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape of training set is : (55000, 28, 28)\n",
      "Example of lable: [4 0 7 9 9 9 4 4 3 4]\n"
     ]
    }
   ],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "# a, b = 1, 2\n",
    "# [axis1, axis2, axis3]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "print(\"Data shape of training set is : {}\".format(X_train.shape))\n",
    "print(\"Example of lable: {}\".format(y_train[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the class of the first image: Coat\n"
     ]
    }
   ],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "    \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "print(\"What is the class of the first image: {}\".format(class_names[y_train[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\", kernel_initializer=\"he_normal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "# is the batchnormalization layer after activation or before?\n",
    "'''\n",
    "\n",
    "'''\n",
    "model = keras.models.Sequential([\n",
    "keras.layers.Flatten(input_shape=[28, 28]),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.Dense(300, kernel_initializer=\"he_normal\", use_bias=False),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.Activation(\"elu\"),\n",
    "keras.layers.Dense(100, kernel_initializer=\"he_normal\", use_bias=False),\n",
    "keras.layers.Activation(\"elu\"),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 300)\n"
     ]
    }
   ],
   "source": [
    "weights, biases = model.layers[1].get_weights()\n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer=\"sgd\",\n",
    "        metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.6944 - accuracy: 0.7718 - val_loss: 0.5036 - val_accuracy: 0.8306\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.4797 - accuracy: 0.8341 - val_loss: 0.4493 - val_accuracy: 0.8470\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 3s 62us/sample - loss: 0.4380 - accuracy: 0.8463 - val_loss: 0.4057 - val_accuracy: 0.8634\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 3s 59us/sample - loss: 0.4102 - accuracy: 0.8565 - val_loss: 0.3844 - val_accuracy: 0.8710\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 4s 73us/sample - loss: 0.3904 - accuracy: 0.8632 - val_loss: 0.3895 - val_accuracy: 0.8640\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 3s 62us/sample - loss: 0.3740 - accuracy: 0.8691 - val_loss: 0.3689 - val_accuracy: 0.8744\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 3s 61us/sample - loss: 0.3608 - accuracy: 0.8741 - val_loss: 0.3624 - val_accuracy: 0.8762\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 4s 67us/sample - loss: 0.3495 - accuracy: 0.8762 - val_loss: 0.3815 - val_accuracy: 0.8666\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 3s 57us/sample - loss: 0.3390 - accuracy: 0.8803 - val_loss: 0.3562 - val_accuracy: 0.8774\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 3s 63us/sample - loss: 0.3297 - accuracy: 0.8827 - val_loss: 0.3459 - val_accuracy: 0.8790\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 4s 65us/sample - loss: 0.3199 - accuracy: 0.8866 - val_loss: 0.3718 - val_accuracy: 0.8678\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 3s 55us/sample - loss: 0.3138 - accuracy: 0.8879 - val_loss: 0.3457 - val_accuracy: 0.8784\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 3s 62us/sample - loss: 0.3054 - accuracy: 0.8908 - val_loss: 0.3297 - val_accuracy: 0.8850\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.2987 - accuracy: 0.8925 - val_loss: 0.3465 - val_accuracy: 0.8752\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.2924 - accuracy: 0.8961 - val_loss: 0.3206 - val_accuracy: 0.8866\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.2864 - accuracy: 0.8968 - val_loss: 0.3288 - val_accuracy: 0.8848\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.2806 - accuracy: 0.8993 - val_loss: 0.3204 - val_accuracy: 0.8862\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 3s 63us/sample - loss: 0.2757 - accuracy: 0.9010 - val_loss: 0.3138 - val_accuracy: 0.8924\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 4s 67us/sample - loss: 0.2701 - accuracy: 0.9020 - val_loss: 0.3215 - val_accuracy: 0.8854\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 3s 59us/sample - loss: 0.2639 - accuracy: 0.9048 - val_loss: 0.3148 - val_accuracy: 0.8862\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 4s 64us/sample - loss: 0.2595 - accuracy: 0.9064 - val_loss: 0.3011 - val_accuracy: 0.8928\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 3s 59us/sample - loss: 0.2553 - accuracy: 0.9081 - val_loss: 0.3242 - val_accuracy: 0.8834\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 4s 80us/sample - loss: 0.2510 - accuracy: 0.9103 - val_loss: 0.3147 - val_accuracy: 0.8872\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.2452 - accuracy: 0.9129 - val_loss: 0.3096 - val_accuracy: 0.8912\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 4s 79us/sample - loss: 0.2416 - accuracy: 0.9129 - val_loss: 0.3023 - val_accuracy: 0.8912\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 4s 81us/sample - loss: 0.2373 - accuracy: 0.9152 - val_loss: 0.2943 - val_accuracy: 0.8932\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.2335 - accuracy: 0.9159 - val_loss: 0.3040 - val_accuracy: 0.8906\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 4s 77us/sample - loss: 0.2293 - accuracy: 0.9176 - val_loss: 0.3100 - val_accuracy: 0.8898\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 4s 81us/sample - loss: 0.2252 - accuracy: 0.9195 - val_loss: 0.2993 - val_accuracy: 0.8958\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.2207 - accuracy: 0.9208 - val_loss: 0.2902 - val_accuracy: 0.8942\n"
     ]
    }
   ],
   "source": [
    "# we want to save the model during training. By default, after the last epoch, model will be saved\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\",\n",
    "        save_best_only=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "        validation_data=(X_valid, y_valid), callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[9 2 1]\n",
      "['Ankle boot' 'Pullover' 'Trouser']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "print(y_proba.round(3))\n",
    "y_pred = model.predict_classes(X_new)\n",
    "print(y_pred)\n",
    "print(np.array(class_names)[list(y_pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "54336/55000 [============================>.] - ETA: 0s - loss: 0.2322 - accuracy: 0.9164\n",
      "val/train: 1.27\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.2317 - accuracy: 0.9165 - val_loss: 0.2938 - val_accuracy: 0.8918\n",
      "Epoch 2/100\n",
      "54080/55000 [============================>.] - ETA: 0s - loss: 0.2276 - accuracy: 0.9175\n",
      "val/train: 1.34\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.2274 - accuracy: 0.9176 - val_loss: 0.3055 - val_accuracy: 0.8874\n",
      "Epoch 3/100\n",
      "54368/55000 [============================>.] - ETA: 0s - loss: 0.2244 - accuracy: 0.9182\n",
      "val/train: 1.45\n",
      "55000/55000 [==============================] - 3s 57us/sample - loss: 0.2241 - accuracy: 0.9185 - val_loss: 0.3254 - val_accuracy: 0.8788\n",
      "Epoch 4/100\n",
      "54144/55000 [============================>.] - ETA: 0s - loss: 0.2203 - accuracy: 0.9212\n",
      "val/train: 1.36\n",
      "55000/55000 [==============================] - 3s 57us/sample - loss: 0.2196 - accuracy: 0.9215 - val_loss: 0.2991 - val_accuracy: 0.8924\n",
      "Epoch 5/100\n",
      "54784/55000 [============================>.] - ETA: 0s - loss: 0.2168 - accuracy: 0.9219\n",
      "val/train: 1.37\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.2165 - accuracy: 0.9220 - val_loss: 0.2971 - val_accuracy: 0.8944\n",
      "Epoch 6/100\n",
      "54848/55000 [============================>.] - ETA: 0s - loss: 0.2143 - accuracy: 0.9227\n",
      "val/train: 1.50\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.2142 - accuracy: 0.9227 - val_loss: 0.3204 - val_accuracy: 0.8836\n",
      "Epoch 7/100\n",
      "54592/55000 [============================>.] - ETA: 0s - loss: 0.2099 - accuracy: 0.9251\n",
      "val/train: 1.42\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.2098 - accuracy: 0.9251 - val_loss: 0.2985 - val_accuracy: 0.8978\n",
      "Epoch 8/100\n",
      "54272/55000 [============================>.] - ETA: 0s - loss: 0.2075 - accuracy: 0.9258\n",
      "val/train: 1.47\n",
      "55000/55000 [==============================] - 3s 57us/sample - loss: 0.2073 - accuracy: 0.9259 - val_loss: 0.3054 - val_accuracy: 0.8916\n",
      "Epoch 9/100\n",
      "54816/55000 [============================>.] - ETA: 0s - loss: 0.2036 - accuracy: 0.9272\n",
      "val/train: 1.65\n",
      "55000/55000 [==============================] - 3s 55us/sample - loss: 0.2037 - accuracy: 0.9271 - val_loss: 0.3357 - val_accuracy: 0.8822\n",
      "Epoch 10/100\n",
      "54816/55000 [============================>.] - ETA: 0s - loss: 0.2002 - accuracy: 0.9270\n",
      "val/train: 1.45\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.2002 - accuracy: 0.9270 - val_loss: 0.2906 - val_accuracy: 0.8948\n",
      "Epoch 11/100\n",
      "54208/55000 [============================>.] - ETA: 0s - loss: 0.1967 - accuracy: 0.9285\n",
      "val/train: 1.47\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.1967 - accuracy: 0.9286 - val_loss: 0.2891 - val_accuracy: 0.8936\n",
      "Epoch 12/100\n",
      "54752/55000 [============================>.] - ETA: 0s - loss: 0.1931 - accuracy: 0.9315\n",
      "val/train: 1.52\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.1931 - accuracy: 0.9316 - val_loss: 0.2942 - val_accuracy: 0.8966\n",
      "Epoch 13/100\n",
      "54048/55000 [============================>.] - ETA: 0s - loss: 0.1906 - accuracy: 0.9318\n",
      "val/train: 1.70\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.1910 - accuracy: 0.9317 - val_loss: 0.3241 - val_accuracy: 0.8838\n",
      "Epoch 14/100\n",
      "54304/55000 [============================>.] - ETA: 0s - loss: 0.1882 - accuracy: 0.9327\n",
      "val/train: 1.63\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.1881 - accuracy: 0.9328 - val_loss: 0.3075 - val_accuracy: 0.8982\n",
      "Epoch 15/100\n",
      "54240/55000 [============================>.] - ETA: 0s - loss: 0.1851 - accuracy: 0.9332\n",
      "val/train: 1.60\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.1853 - accuracy: 0.9331 - val_loss: 0.2959 - val_accuracy: 0.8986\n",
      "Epoch 16/100\n",
      "54272/55000 [============================>.] - ETA: 0s - loss: 0.1819 - accuracy: 0.9344\n",
      "val/train: 1.61\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.1814 - accuracy: 0.9346 - val_loss: 0.2918 - val_accuracy: 0.8952\n",
      "Epoch 17/100\n",
      "54912/55000 [============================>.] - ETA: 0s - loss: 0.1790 - accuracy: 0.9356\n",
      "val/train: 1.64\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.1789 - accuracy: 0.9357 - val_loss: 0.2933 - val_accuracy: 0.8962\n",
      "Epoch 18/100\n",
      "54656/55000 [============================>.] - ETA: 0s - loss: 0.1756 - accuracy: 0.9371\n",
      "val/train: 1.64\n",
      "55000/55000 [==============================] - 3s 57us/sample - loss: 0.1756 - accuracy: 0.9371 - val_loss: 0.2874 - val_accuracy: 0.8986\n",
      "Epoch 19/100\n",
      "54656/55000 [============================>.] - ETA: 0s - loss: 0.1731 - accuracy: 0.9389\n",
      "val/train: 1.67\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.1733 - accuracy: 0.9389 - val_loss: 0.2897 - val_accuracy: 0.9002\n",
      "Epoch 20/100\n",
      "54400/55000 [============================>.] - ETA: 0s - loss: 0.1700 - accuracy: 0.9394\n",
      "val/train: 1.78\n",
      "55000/55000 [==============================] - 3s 57us/sample - loss: 0.1701 - accuracy: 0.9393 - val_loss: 0.3020 - val_accuracy: 0.8982\n",
      "Epoch 21/100\n",
      "54016/55000 [============================>.] - ETA: 0s - loss: 0.1691 - accuracy: 0.9398\n",
      "val/train: 1.80\n",
      "55000/55000 [==============================] - 3s 57us/sample - loss: 0.1692 - accuracy: 0.9397 - val_loss: 0.3053 - val_accuracy: 0.8950\n",
      "Epoch 22/100\n",
      "54912/55000 [============================>.] - ETA: 0s - loss: 0.1651 - accuracy: 0.9411\n",
      "val/train: 1.82\n",
      "55000/55000 [==============================] - 3s 57us/sample - loss: 0.1652 - accuracy: 0.9410 - val_loss: 0.3003 - val_accuracy: 0.8966\n",
      "Epoch 23/100\n",
      "54880/55000 [============================>.] - ETA: 0s - loss: 0.1617 - accuracy: 0.9425\n",
      "val/train: 1.78\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.1620 - accuracy: 0.9424 - val_loss: 0.2885 - val_accuracy: 0.8976\n",
      "Epoch 24/100\n",
      "54944/55000 [============================>.] - ETA: 0s - loss: 0.1589 - accuracy: 0.9436\n",
      "val/train: 1.84\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.1588 - accuracy: 0.9436 - val_loss: 0.2925 - val_accuracy: 0.8994\n",
      "Epoch 25/100\n",
      "54976/55000 [============================>.] - ETA: 0s - loss: 0.1574 - accuracy: 0.9441\n",
      "val/train: 1.97\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.1574 - accuracy: 0.9441 - val_loss: 0.3103 - val_accuracy: 0.8934\n",
      "Epoch 26/100\n",
      "54336/55000 [============================>.] - ETA: 0s - loss: 0.1551 - accuracy: 0.9442\n",
      "val/train: 2.03\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.1559 - accuracy: 0.9438 - val_loss: 0.3163 - val_accuracy: 0.8872\n",
      "Epoch 27/100\n",
      "54784/55000 [============================>.] - ETA: 0s - loss: 0.1520 - accuracy: 0.9464\n",
      "val/train: 2.11\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.1520 - accuracy: 0.9464 - val_loss: 0.3210 - val_accuracy: 0.8930\n",
      "Epoch 28/100\n",
      "54752/55000 [============================>.] - ETA: 0s - loss: 0.1495 - accuracy: 0.9472\n",
      "val/train: 2.12\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.1495 - accuracy: 0.9472 - val_loss: 0.3168 - val_accuracy: 0.8934\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model2.h5\",\n",
    "    save_best_only=True)\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "        restore_best_weights=True)\n",
    "\n",
    "# define a customized callback object\n",
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f} \\n\".format(logs[\"val_loss\"] / logs[\"loss\"]))\n",
    "\n",
    "import os # os module handles system paths\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir) \n",
    "# open tensorboard: '$ tensorboard --logdir=./my_logs --port=6006' in your terminal\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "        validation_data=(X_valid, y_valid), \n",
    "        callbacks=[checkpoint_cb, early_stopping_cb, PrintValTrainRatioCallback(), tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
